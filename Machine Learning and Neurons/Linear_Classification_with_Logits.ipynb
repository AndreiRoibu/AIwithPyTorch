{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Classification with Logits.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruyxiJl6z7Y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the relevant modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWZnooyj0JkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data\n",
        "data = load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXaR01g60NC6",
        "colab_type": "code",
        "outputId": "16b11cda-71ae-485f-8d2f-29c4c858d0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check data properties\n",
        "print(\"Type:\", type(data))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: <class 'sklearn.utils.Bunch'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxJEAoIf0Vy6",
        "colab_type": "code",
        "outputId": "4f3e0bd5-c458-4fee-88fd-a65d383bbe12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print(\"Keys:\", data.keys()) # Shows the keys of the data\n",
        "print(\"Shape:\", data.data.shape) # Check the shape of X\n",
        "print(\"Targets:\", data.target.shape) # Check the shape of Y\n",
        "print(\"Feature Names:\", data.feature_names) # Print the input feature names\n",
        "print(\"Targets Names:\", data.target_names)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys: dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
            "Shape: (569, 30)\n",
            "Targets: (569,)\n",
            "Feature Names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "Targets Names: ['malignant' 'benign']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy_cojkJ0yzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We split the data into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size = 0.33)\n",
        "N, D = X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLMYA4D-1N7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We scale the data\n",
        "# StandardScaler is used for normalizing the data\n",
        "# This is to prevent inputs from having very different ranges\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODhgGhPg1ejz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We build the model\n",
        "# Sigmoid to make sure the output is 0/1 \n",
        "\n",
        "\"\"\"\n",
        "Motivation - numerical instability.\n",
        "Exponential numbers tend to be very large\n",
        "In the sigmoid, the operation is exponential, which is unstable\n",
        "The log term in Binary Cross-Entropy is unstable, because of similar reasons\n",
        "Because the BCE has a log, it cancels our the exponential.\n",
        "For both Sigmoid and BCE, these can be combined, and express the loss in terms of the activation (aka logit)\n",
        "The logit is the input into the logistic/sigmoid function.\n",
        "\"\"\"\n",
        "\n",
        "model = nn.Linear(D, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-kiRzEGQIUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss and optimizer\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y20Eh4nQYnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We convert the data into Torch Tensors\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "\n",
        "# Targets are reshaped to be 2D arrays of shape Nx1\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32).reshape(-1, 1))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32).reshape(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh66Ivg6Q1LB",
        "colab_type": "code",
        "outputId": "c2e0ca6d-6111-4156-e4bc-725860a92083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "source": [
        "# Train the model\n",
        "number_epochs = 2000\n",
        "train_losses = np.zeros(number_epochs)\n",
        "test_losses = np.zeros(number_epochs)\n",
        "\n",
        "for iteration in range(number_epochs):\n",
        "\n",
        "    # We train the model\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # We are also interested in the test/validation loss, to make sure we are not overtiffing\n",
        "    outputs_test = model(X_test)\n",
        "    loss_test = criterion(outputs_test, y_test)\n",
        "\n",
        "    # We save the losses\n",
        "    train_losses[iteration] = loss.item()\n",
        "    test_losses[iteration] = loss_test.item()\n",
        "\n",
        "    if (iteration+1) % 50 == 0:\n",
        "        print(\"Epoch: {}/{}, Train Loss: {}, Test Loss: {}\".format(iteration+1, number_epochs, loss.item(), loss_test.item()))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 50/2000, Train Loss: 0.542561411857605, Test Loss: 0.5740674734115601\n",
            "Epoch: 100/2000, Train Loss: 0.3913623094558716, Test Loss: 0.4023183584213257\n",
            "Epoch: 150/2000, Train Loss: 0.31181907653808594, Test Loss: 0.3171365559101105\n",
            "Epoch: 200/2000, Train Loss: 0.2626412510871887, Test Loss: 0.2665656805038452\n",
            "Epoch: 250/2000, Train Loss: 0.22915086150169373, Test Loss: 0.23278281092643738\n",
            "Epoch: 300/2000, Train Loss: 0.2049051970243454, Test Loss: 0.20850174129009247\n",
            "Epoch: 350/2000, Train Loss: 0.18658024072647095, Test Loss: 0.19017094373703003\n",
            "Epoch: 400/2000, Train Loss: 0.17226728796958923, Test Loss: 0.17583324015140533\n",
            "Epoch: 450/2000, Train Loss: 0.16078901290893555, Test Loss: 0.1643122136592865\n",
            "Epoch: 500/2000, Train Loss: 0.1513819396495819, Test Loss: 0.15485462546348572\n",
            "Epoch: 550/2000, Train Loss: 0.1435309499502182, Test Loss: 0.14695453643798828\n",
            "Epoch: 600/2000, Train Loss: 0.13687683641910553, Test Loss: 0.14025893807411194\n",
            "Epoch: 650/2000, Train Loss: 0.13116206228733063, Test Loss: 0.13451382517814636\n",
            "Epoch: 700/2000, Train Loss: 0.12619753181934357, Test Loss: 0.1295316517353058\n",
            "Epoch: 750/2000, Train Loss: 0.12184140086174011, Test Loss: 0.1251710057258606\n",
            "Epoch: 800/2000, Train Loss: 0.11798538267612457, Test Loss: 0.12132316082715988\n",
            "Epoch: 850/2000, Train Loss: 0.11454543471336365, Test Loss: 0.11790312081575394\n",
            "Epoch: 900/2000, Train Loss: 0.11145522445440292, Test Loss: 0.11484361439943314\n",
            "Epoch: 950/2000, Train Loss: 0.10866186022758484, Test Loss: 0.1120905801653862\n",
            "Epoch: 1000/2000, Train Loss: 0.10612263530492783, Test Loss: 0.10960017144680023\n",
            "Epoch: 1050/2000, Train Loss: 0.1038026288151741, Test Loss: 0.10733643919229507\n",
            "Epoch: 1100/2000, Train Loss: 0.10167312622070312, Test Loss: 0.10526968538761139\n",
            "Epoch: 1150/2000, Train Loss: 0.09971018135547638, Test Loss: 0.10337503254413605\n",
            "Epoch: 1200/2000, Train Loss: 0.09789372235536575, Test Loss: 0.10163166373968124\n",
            "Epoch: 1250/2000, Train Loss: 0.09620685875415802, Test Loss: 0.10002198070287704\n",
            "Epoch: 1300/2000, Train Loss: 0.09463515877723694, Test Loss: 0.09853096306324005\n",
            "Epoch: 1350/2000, Train Loss: 0.09316626936197281, Test Loss: 0.09714575111865997\n",
            "Epoch: 1400/2000, Train Loss: 0.09178952872753143, Test Loss: 0.09585531055927277\n",
            "Epoch: 1450/2000, Train Loss: 0.09049580991268158, Test Loss: 0.0946500226855278\n",
            "Epoch: 1500/2000, Train Loss: 0.08927704393863678, Test Loss: 0.09352163225412369\n",
            "Epoch: 1550/2000, Train Loss: 0.08812632411718369, Test Loss: 0.09246286749839783\n",
            "Epoch: 1600/2000, Train Loss: 0.08703739196062088, Test Loss: 0.09146738052368164\n",
            "Epoch: 1650/2000, Train Loss: 0.08600490540266037, Test Loss: 0.09052955359220505\n",
            "Epoch: 1700/2000, Train Loss: 0.08502405881881714, Test Loss: 0.08964445441961288\n",
            "Epoch: 1750/2000, Train Loss: 0.08409052342176437, Test Loss: 0.08880768716335297\n",
            "Epoch: 1800/2000, Train Loss: 0.08320056647062302, Test Loss: 0.08801538497209549\n",
            "Epoch: 1850/2000, Train Loss: 0.08235076069831848, Test Loss: 0.0872640535235405\n",
            "Epoch: 1900/2000, Train Loss: 0.08153807371854782, Test Loss: 0.08655059337615967\n",
            "Epoch: 1950/2000, Train Loss: 0.080759696662426, Test Loss: 0.08587222546339035\n",
            "Epoch: 2000/2000, Train Loss: 0.08001323789358139, Test Loss: 0.0852264016866684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5j_t3GIY3cZ",
        "colab_type": "code",
        "outputId": "62474222-7a04-4efe-bf62-260de385c586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Plot the train and test losses\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(test_losses, label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIe_WyT2aXZs",
        "colab_type": "code",
        "outputId": "5f7ad7ff-36ea-4d90-9a74-7c07c7ca4d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the accuracy\n",
        "# Sigmoid always outputs a number between 0 and 1 and this is a probability\n",
        "# For logits, the predictions are positive or negative (sides of hyperplane)\n",
        "with torch.no_grad():\n",
        "    p_train = model(X_train) # Calculate the prediction\n",
        "    p_train = (p_train.numpy()> 0) # convert tensors to np, and round them\n",
        "    train_accuracy = np.mean(y_train.numpy() == p_train) # point-wise comparison and take the mean\n",
        "\n",
        "    p_test = model(X_test)\n",
        "    p_test = (p_test.numpy() > 0)\n",
        "    test_accuracy = np.mean(y_test.numpy() == p_test)\n",
        "\n",
        "print('Train Accuracy: {}, Test Accuracy: {}'.format(train_accuracy, test_accuracy))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.9868766404199475, Test Accuracy: 0.9574468085106383\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}