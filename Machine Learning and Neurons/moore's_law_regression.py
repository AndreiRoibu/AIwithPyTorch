# -*- coding: utf-8 -*-
"""Moore's Law Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yocvCyCj6ndWg6Mqms_hejcorw50L8QP
"""

# We first get all the relevant imports
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# We get the data
!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/tf2.0/moore.csv

# Load the data 
data = pd.read_csv('moore.csv', header=None).values # Load as numpy
X = data[:,0].reshape(-1,1) # 2D array of size NxD, D=1
y = data[:,1].reshape(-1,1)

# Plot the data
plt.scatter(X,y)

# A linear model is desired, so we take the log
y = np.log(y)
plt.scatter(X,y)

# We perform data pre-processing
# The data is standardized/normalized for X and y
mean_X = X.mean()
std_X = X.std()
mean_y = y.mean()
std_y = y.std()

# We keep the above as variables, to reverse transformations and go back to orig. units.

X = (X - mean_X) / std_X
y = (y - mean_y) / std_y

plt.scatter(X,y)

X = X.astype(np.float32)
y = y.astype(np.float32)

# Create the linear regression model
model = nn.Linear(1,1)

# Loss and Optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.7)

# Prepare the data
inputs = torch.from_numpy(X)
targets = torch.from_numpy(y)

# Train the model
number_epochs = 100
losses = []
for iteration in range(number_epochs):
    optimizer.zero_grad()
    outputs = model(inputs)
    loss = criterion(outputs, targets)
    losses.append(loss.item())
    loss.backward()
    optimizer.step()
    print("Epoch {}/{}, Loss: {}".format(iteration+1, number_epochs, loss.item()))

# Loss per iter
plt.plot(losses)

# Plot the line of best fit
predicted = model(torch.from_numpy(X)).detach().numpy()
plt.plot(X, y, 'ro', label='original data')
plt.plot(X, predicted, label='Fitted Line')
plt.legend()
plt.show()

# Weights:
w = model.weight.data.numpy()
print(w)

a = w[0,0] * std_y / std_X

print("Doubling time:", np.log(2) / a)

